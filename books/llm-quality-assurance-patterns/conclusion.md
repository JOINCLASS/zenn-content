---
title: "おわりに — LLMアプリの品質保証5原則"
free: true
---

## LLMアプリの品質保証5原則

本書を通じて解説してきた内容を、5つの原則として整理します。

### 原則1: LLMの出力を信用しない

LLMは確率的にテキストを生成するシステムであり、出力の正確性を自ら保証できません。どれだけプロンプトを工夫しても、バリデーションなしで本番環境にLLM出力を流すべきではありません。

構造バリデーション、コンテンツバリデーション、フィードバックループの3層で品質を担保する設計が必要です。

### 原則2: 品質問題は分類してから対策する

「AIの出力がおかしい」で終わらせず、ハルシネーション・構造的不整合・難易度不適切・曖昧性の4カテゴリに分類することで、適切な対策を打てるようになります。検出が容易で影響度が高いもの（構造的不整合）から優先的に取り組みましょう。

### 原則3: プロンプトは最もレバレッジの高い品質投資

バリデーションは事後対処ですが、プロンプトの改善は品質問題の発生そのものを減らします。JSON Schema指定、Temperature最適化、ソーステキスト参照の強制、Few-shot例の提示——これらのテクニックを組み合わせることで、後工程のバリデーション負荷を大幅に削減できます。

### 原則4: ユーザー行動データを品質センサーとして活用する

SM-2アルゴリズムのrepetitionsとeaseFactorは、ユーザーの記憶定着を最適化するだけでなく、AI生成コンテンツの品質を測定するセンサーとしても機能します。ユーザーの学習行動をフィードバックループとして設計することで、運用しながら品質を継続的に改善できます。

### 原則5: テストを非決定論に適応させる

LLM出力のテストは、従来のアサーションベースのテストでは不十分です。決定論的テスト（構造検証）、統計的テスト（品質分布の検証）、ゴールデンデータセット（基準との比較）を組み合わせたテストピラミッドを構築しましょう。

## 今後の展望

### Structured Output の標準化

2026年現在、Gemini APIとOpenAI APIの両方がStructured Output（構造化出力）をサポートしています。JSON Schemaを直接指定できることで、構造的不整合の問題は大幅に軽減されました。今後はこの機能がさらに進化し、より複雑な出力制約の指定が可能になるでしょう。

### マルチモーダルの進化

MochiQでは画像（教材の写真）からクイズを生成していますが、動画、音声、手書きノートのリアルタイム認識など、入力モダリティの拡大が進んでいます。入力が多様になるほど、品質問題のパターンも増えるため、バリデーションアーキテクチャの拡張が求められます。

### ファインチューニングによる品質向上

汎用モデルのプロンプトエンジニアリングには限界があります。教育コンテンツ生成に特化したファインチューニングモデルを用意することで、ハルシネーション率と難易度制御の精度を向上させる道があります。ただし、ファインチューニングには高品質なトレーニングデータの確保という別の課題が伴います。

### Tool Use（関数呼び出し）との統合

LLMにバリデーション関数を「ツール」として提供し、生成と検証を一体化するアプローチも注目されています。LLM自身が生成したクイズを自ら検証関数に通し、問題があれば再生成する——というセルフヒーリングのパイプラインが実現しつつあります。

## MochiQを使ってみる

本書で解説した品質保証パターンは、すべて教育AIアプリ「MochiQ」で実装・運用されています。教材を撮影するだけでAIがクイズを自動生成し、SM-2アルゴリズムで最適なタイミングに出題します。

iOS / Android対応。無料で使えます。

https://mochiq.joinclass.jp

本書の内容についてのフィードバックや質問があれば、Zennのコメント欄でお待ちしています。LLMアプリの品質保証は、まだ発展途上の領域です。皆さんの知見を共有し合うことで、この分野を一緒に前進させていきましょう。

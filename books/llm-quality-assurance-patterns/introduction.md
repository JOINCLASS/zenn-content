---
title: "はじめに — AIが生成するコンテンツの品質保証という新しい課題"
free: true
---

## 従来のソフトウェアにはなかった問題

ソフトウェア開発における品質保証（QA）には長い歴史があります。ユニットテスト、結合テスト、E2Eテスト——確立された手法に従えば、「同じ入力に対して同じ出力が返る」ことを検証できました。

しかし、LLM（大規模言語モデル）を組み込んだアプリケーションでは、この前提が根本から崩れます。

同じプロンプトを同じモデルに投げても、返ってくる結果は毎回異なります。生成されたテキストが事実として正しいかどうかは、モデル自身には判断できません。出力のフォーマットが仕様通りである保証もありません。つまり、LLMアプリの品質保証とは「非決定論的な出力をどう制御するか」という、従来のQAとはまったく異なる問題と向き合うことを意味します。

## 教育AIアプリ「MochiQ」の開発で直面したこと

筆者は教育AIアプリ「MochiQ」を開発・運用しています。MochiQは、ユーザーが教材をスマホのカメラで撮影すると、AIが自動でクイズを生成し、SM-2アルゴリズムによるスペースドリピティション（間隔反復学習）で記憶の定着を支援するアプリです。

このアプリの品質は、AIが生成するクイズの品質に直結します。具体的には、以下のような問題に日々直面しています。

- **ハルシネーション**: 教材に書かれていない内容でクイズが生成される
- **構造的不整合**: JSONの破損、必須フィールドの欠落、選択肢の数が仕様と異なる
- **難易度のミスマッチ**: 小学生向けなのに大学レベルの問題が出題される
- **曖昧な問題**: 正解が複数あり得る問題、意図が不明瞭な問題

これらはすべて、ユーザーの学習効果を直接損なう品質問題です。テストを書いて回避できるような単純なバグではありません。

## 本書で学べること

本書では、MochiQの開発・運用経験を通じて得た、LLMアプリの品質保証パターンを体系的に解説します。

1. **写真→クイズ生成パイプラインの全体設計** — マルチモーダルAIを活用したパイプラインの構築方法
2. **AI生成コンテンツの品質問題の分類** — 問題を4カテゴリに整理し、対策の優先度を判断する方法
3. **3層バリデーションアーキテクチャ** — 構造・コンテンツ・フィードバックの3層で品質を担保する設計
4. **プロンプトエンジニアリング** — JSON Schema指定、Temperature最適化、Few-shotの実践テクニック
5. **ハルシネーション検出** — ソース照合、Cross-validation、Confidence scoringの実装
6. **フィードバックループの設計** — SM-2アルゴリズムとユーザー行動データによる品質改善
7. **コスト最適化** — キャッシュ戦略、モデルの使い分け、画像前処理による無駄の削減
8. **LLM出力のテスト戦略** — 決定論的テスト、統計的テスト、CI/CDでの自動化

コード例はDart（Flutter）とTypeScript（Node.js）の両方で示します。ただし、パターンそのものは言語やフレームワークに依存しないため、Python、Go、Rustなど他の言語で開発している方にも応用できます。

## 対象読者

- **LLMアプリ開発者**: ChatGPT API、Gemini API、Claude APIなどを使ったアプリを開発している方
- **EdTech開発者**: AIを活用した教育プロダクトを開発している方
- **PM・プロダクトオーナー**: AI機能の品質基準をどう設定するか悩んでいる方
- **QAエンジニア**: LLMを組み込んだシステムのテスト戦略を検討している方

2026年現在、Structured Output（構造化出力）やTool Use（関数呼び出し）の普及により、LLM出力の制御性は大幅に向上しています。しかし、コンテンツの品質——つまり「生成された内容が正しく、適切で、ユーザーにとって有益か」を保証する問題は、依然として開発者が自ら設計しなければならない領域です。

本書が、その設計の指針となれば幸いです。

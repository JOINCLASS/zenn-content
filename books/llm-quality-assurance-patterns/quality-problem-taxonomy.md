---
title: "AI生成コンテンツの品質問題を分類する"
---

## なぜ分類が必要なのか

LLMアプリの品質問題は多岐にわたります。「AIの出力がおかしい」という漠然とした認識のままでは、対策を体系的に打つことができません。本章では、MochiQの開発・運用で実際に遭遇した品質問題を4つのカテゴリに分類し、各カテゴリの特徴と影響度を整理します。

## カテゴリ1: ハルシネーション（事実と異なる情報の生成）

最も深刻な品質問題です。教材に書かれていない情報をLLMが「創作」してしまうケースを指します。

### 具体例

ユーザーが日本史の教科書を撮影した場合を考えます。教科書には「鎌倉幕府は1185年に成立した」と記載されているのに、LLMが以下のようなクイズを生成するケースがあります。

```json
{
  "question": "鎌倉幕府の初代執権は誰か？",
  "answers": ["北条時政", "北条義時", "北条泰時", "北条時頼"],
  "correct": "北条時政"
}
```

この問題自体は事実として正しいですが、教材の内容とは無関係です。LLMは自身の学習データから「鎌倉幕府に関連する知識」を引き出してクイズを作ってしまいました。教材には執権に関する記述はなかったにもかかわらず。

### 教育コンテンツにおけるリスク

教育アプリにおけるハルシネーションは、一般的なチャットボットよりも深刻です。ユーザー（特に学生）はAIが生成したクイズを「正しい学習素材」として信頼します。誤った情報を含むクイズで学習すると、誤った知識が定着してしまいます。間違いを覚えることは、何も知らないことよりも害が大きいのです。

### 発生頻度の目安

MochiQの初期バージョンでは、生成されるクイズの約8-12%にハルシネーションが含まれていました。対策後は2-3%まで低減していますが、完全なゼロにはできていません。

## カテゴリ2: 構造的不整合

LLMの出力がプログラムで処理できない構造になっているケースです。JSON破損、フィールド欠落、データ型の不一致などが含まれます。

### 具体例

4択問題を要求しているのに、選択肢が3つしかない場合。

```json
{
  "question": "光合成に必要なものはどれか？",
  "answers": ["水", "二酸化炭素", "光"],
  "correct": "水",
  "type": "multiple_choice"
}
```

あるいは、JSONの閉じ括弧が欠落してパースが失敗する場合。

```
{
  "title": "理科クイズ",
  "questions": [
    {
      "question": "水の沸点は何度か？",
      "answers": ["80度", "90度", "100度", "110度"],
      "correct": "100度"
    }
  // ← 閉じ括弧が欠落
```

### 構造的不整合のパターン

MochiQで観測した構造的不整合のパターンを整理すると以下の通りです。

| パターン | 発生頻度 | 影響度 |
|---------|---------|-------|
| JSONパースエラー（閉じ括弧欠落、不正なエスケープ） | 低（1-2%） | 致命的 |
| 必須フィールドの欠落（`correct`フィールドがない等） | 中（3-5%） | 致命的 |
| 選択肢数の不一致（4択なのに3つ） | 中（5-8%） | 高 |
| データ型の不一致（数値のはずが文字列） | 低（1-3%） | 中 |
| 正解が選択肢に含まれていない | 中（3-5%） | 致命的 |
| マークダウンやHTMLタグの混入 | 高（10-15%） | 低 |

2026年現在、Gemini APIやOpenAI APIのStructured Output機能を使えば、JSON構造の不整合は大幅に低減できます。しかし、「正解が選択肢に含まれていない」のような意味的な構造不整合は、Structured Outputだけでは防げません。

## カテゴリ3: 難易度の不適切さ

生成されたコンテンツの難易度がユーザーの学習レベルと合っていないケースです。

### 具体例

小学3年生が理科の教科書を撮影したのに、以下のようなクイズが生成される場合。

```json
{
  "question": "光合成の化学反応式として正しいものはどれか？",
  "answers": [
    "6CO₂ + 6H₂O → C₆H₁₂O₆ + 6O₂",
    "6CO₂ + 12H₂O → C₆H₁₂O₆ + 6O₂ + 6H₂O",
    "CO₂ + H₂O → CH₂O + O₂",
    "2CO₂ + 2H₂O → 2CH₂O + 2O₂"
  ],
  "correct": "6CO₂ + 6H₂O → C₆H₁₂O₆ + 6O₂"
}
```

化学反応式は中学〜高校レベルの内容です。小学3年生がこの問題を出題されても、学習効果はありません。

### 難易度制御の難しさ

LLMは「対象学年に合わせた難易度で出題してください」という指示に対して、ある程度は対応できます。しかし、以下のケースでは制御が困難です。

- 教材そのものが高度な内容を含んでいる場合（教材の難易度とユーザーの学年の不一致）
- 専門用語の平易な言い換えが難しい分野（化学、物理など）
- 同じ単元でも細かい学年差に対応する場合（小5と小6の算数の境界線）

MochiQではプロンプトに `gradeLevel` パラメータを含め、学年に応じた出題を指示していますが、これだけでは不十分なケースが多く、生成後のバリデーションが必要です。

## カテゴリ4: 曖昧な問題

正解が複数あり得る問題や、問題文の意図が不明瞭な問題です。

### 具体例

```json
{
  "question": "日本の首都はどこですか？",
  "answers": ["東京", "東京都", "千代田区", "関東地方"],
  "correct": "東京"
}
```

この問題では「東京」と「東京都」のどちらも正解と言えます。ユーザーが「東京都」を選んで不正解と判定されると、不信感を招きます。

さらに厄介な例を挙げます。

```json
{
  "question": "次のうち、正しいものを選びなさい",
  "answers": [
    "地球は太陽の周りを回っている",
    "月は地球の周りを回っている",
    "太陽は地球の周りを回っている",
    "地球は自転している"
  ],
  "correct": "地球は太陽の周りを回っている"
}
```

「地球は太陽の周りを回っている」「月は地球の周りを回っている」「地球は自転している」の3つが事実として正しいです。このような問題は、ユーザーの学習体験を大きく損ねます。

### 曖昧さの検出が難しい理由

曖昧な問題の検出は、4つのカテゴリの中で最も自動化が難しいものです。問題が曖昧かどうかの判断には、その分野の知識と文脈の理解が必要だからです。後述するフィードバックループ（ユーザーの回答パターンから品質問題を推定する手法）が、この問題に対する現実的な対策になります。

## 品質問題の影響度マトリクス

4つのカテゴリを「検出の容易さ」と「学習効果への影響度」の2軸で整理します。

```
影響度（高）
  ^
  |  ハルシネーション          曖昧な問題
  |    ・検出：中              ・検出：困難
  |    ・自動対策：可能        ・自動対策：部分的
  |
  |  構造的不整合              難易度の不適切さ
  |    ・検出：容易            ・検出：中
  |    ・自動対策：容易        ・自動対策：可能
  |
  +---------------------------------------------> 検出の困難さ
```

この整理から、対策の優先順位が見えてきます。

1. **構造的不整合**: 検出が容易で自動対策も可能。最初に取り組むべき
2. **ハルシネーション**: 影響度が高く、ソース照合による検出が可能。次に取り組む
3. **難易度の不適切さ**: プロンプト設計とメタデータ活用で改善可能
4. **曖昧な問題**: 完全な自動化は困難。フィードバックループで検出し、段階的に改善

次章以降では、これらの問題に対する具体的な対策パターンを、コードレベルで解説していきます。
